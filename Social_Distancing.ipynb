{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social_Distancing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygq4ZQabrDEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive (If using Colab)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"drive/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvGhWHSHfU8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Face detection module from PyPI\n",
        "\n",
        "!pip install face-detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgpQJHNSfsK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Required Packages\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import face_detection "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygki7lR_sFvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path to the main working environment\n",
        "\n",
        "# If using Google Colab\n",
        "BASE_PATH = \"drive/My Drive/Social_Distancing/\"\n",
        "\n",
        "# If on a local environment, no path required  \n",
        "# BASE_PATH  = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xrRSzoT9EBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a face detector\n",
        "\n",
        "# Confidence threshold can be adjusted to detect clear faces\n",
        "detector = face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ejHxuy-9iZwL",
        "colab": {}
      },
      "source": [
        "# Load Yolo v3\n",
        "net = cv2.dnn.readNet(BASE_PATH+\"yolov3.weights\", BASE_PATH+\"yolov3.cfg\")\n",
        "classes = []\n",
        "\n",
        "with open(BASE_PATH+\"coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "    \n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Initialize output video stream\n",
        "out_stream = cv2.VideoWriter(\n",
        "    'output.mkv',\n",
        "    cv2.VideoWriter_fourcc(*'XVID'),\n",
        "    25.,\n",
        "    (1920,1080))\n",
        "\n",
        "# Path to input video file in the BASE_PATH\n",
        "FILE_PATH = \"test.mkv\"\n",
        "cap = cv2.VideoCapture(BASE_PATH + FILE_PATH )\n",
        "\n",
        "frame_count = 0\n",
        "person_count = 0 \n",
        "face_count = 0 \n",
        "\n",
        "while cap.isOpened():\n",
        "    \n",
        "    # Capture frame-by-frame\n",
        "    ret, img = cap.read()\n",
        "\n",
        "    # Checking end of File\n",
        "    if ret == False:\n",
        "        break;\n",
        "\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    # Detecting objects\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    \n",
        "    # Analyze Detected Objects\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                \n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "\n",
        "    # Initialize empty lists\n",
        "    persons = []\n",
        "    faces = []\n",
        "\n",
        "    # Work on detected Persons in the video\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            if label=='person' and (x<0)==False:\n",
        "\n",
        "                person_count += 1\n",
        "                persons.append([x,y,w,h])\n",
        "\n",
        "                # Save cropped person\n",
        "                cv2.imwrite(BASE_PATH + \"extracted_persons/\"+str(frame_count)+\"_\"+str(person_count)+\".png\",img[y:y+h,x:x+w])\n",
        "\n",
        "                # Detect face in the person\n",
        "                # BGR to RGB\n",
        "                detections = detector.detect(img[y:y+h,x:x+w,::-1])\n",
        "\n",
        "                # If a face is detected\n",
        "                if detections.shape[0]>0:\n",
        "                  \n",
        "                  face_count += 1\n",
        "\n",
        "                  # Calculating coordinates of detected face\n",
        "                  x1 = x + int(detections[0][0])\n",
        "                  x2 = x + int(detections[0][2])\n",
        "                  y1 = y + int(detections[0][1])\n",
        "                  y2 = y + int(detections[0][3])\n",
        "\n",
        "                  faces.append([x1,y1,x2,y2])\n",
        "\n",
        "                  # Save cropped face\n",
        "                  cv2.imwrite(BASE_PATH + \"extracted_faces/\"+str(frame_count)+\"_\"+str(face_count)+\".png\",img[y1:y2,x1:x2])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}